order(tblAIC)
View(tblAIC)
tblAIC<-order(tblAIC)
tblAIC<-tblAIC[order(tblAIC)]
tblAIC<-tblAIC[order(tblAIC$AIC)]
tblAIC<-tblAIC[order(tblAIC$AIC),]
bestfit<-step(lm(mpg~., mtcars[,-c(7)]), direction = "both")
bestmodel<-bestfit$call
bfform<-bestmodel$formula
bfform<-paste(bfform[c(2,1,3)], collapse = "")
allAIC=extractAIC(lm(mpg ~ ., mtcars[,-7]))
fitAIC=extractAIC(lm(mpg ~ am, mtcars[,-7]))
bestAIC=extractAIC(bestfit)
tblAIC<-order(rbind("mpg ~ ." = allAIC[2],"mpg ~ am"= fitAIC[2],"mpg ~ wt + cyl + am" = bestAIC[2]))
tblAIC<-as.data.frame(tblAIC)
names(tblAIC)<-"AIC"
tblAIC<-as.data.frame(tblAIC[,])
bestfit<-step(lm(mpg~., mtcars[,-c(7)]), direction = "both")
bestmodel<-bestfit$call
bfform<-bestmodel$formula
bfform<-paste(bfform[c(2,1,3)], collapse = "")
allAIC=extractAIC(lm(mpg ~ ., mtcars[,-7]))
fitAIC=extractAIC(lm(mpg ~ am, mtcars[,-7]))
bestAIC=extractAIC(bestfit)
tblAIC<-as.data.frame(rbind("mpg ~ am"= fitAIC[2],"mpg ~ ." = allAIC[2],"mpg ~ wt + cyl + am" = bestAIC[2]))
names(tblAIC)<-"AIC"
bestfit<-step(lm(mpg~., mtcars[,-c(7)]), direction = "both")
bestmodel<-bestfit$call
bfform<-bestmodel$formula
bfform<-paste(bfform[c(2,1,3)], collapse = "")
allAIC=extractAIC(lm(mpg ~ ., mtcars[,-7]))
fitAIC=extractAIC(lm(mpg ~ am, mtcars[,-7]))
bestAIC=extractAIC(bestfit)
names(tblAIC)<-"AIC"
bestfit<-step(lm(mpg~., mtcars[,-c(7)]), direction = "both")
fitAIC=extractAIC(lm(mpg ~ am, mtcars[,-7]))
allAIC=extractAIC(lm(mpg ~ ., mtcars[,-7]))
bestAIC=extractAIC(bestfit)
tblAIC<-as.data.frame(rbind("mpg ~ am"= fitAIC[2],"mpg ~ ." = allAIC[2],"mpg ~ cyl + hp + wt + am" = bestAIC[2]))
kable(tblAIC, caption = "Comparison of AIC Values of Three Models")
source('~/.active-rstudio-document', echo=TRUE)
```{r, results='asis'}
kable(c4, caption = "Correlation among variables with lowest p-value in analysis of variance model")
cor(mtcars$wt, mtcars$hp)
hatvalues(bestfit)
fit <- lm(hp ~ cyl + mpg, data=mtcars) #a fake model
hatvalues(fit)
hv <- as.data.frame(hatvalues(fit))
mn <-mean(hatvalues(fit))
hv$warn <- ifelse(hv[, 'hatvalues(fit)']>3*mn, 'x3',
ifelse(hv[, 'hatvalues(fit)']>2*mn, 'x3', '-' ))
hv
summary(hatvalues(fit))
source('~/.active-rstudio-document', echo=TRUE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
set.seed(125)
df<-data.frame(segmentationOriginal, predictors)
inTrain<-createDataPartition(y = segmentationOriginal$Case, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
# plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
df<-data.frame(Cells, predictors)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rpart)
set.seed(125)
df<-data.frame(segmentationOriginal$Class, predictors)
inTrain<-createDataPartition(y = df$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
# plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
df<-data.frame(segmentationOriginal$Class, predictors)
inTrain<-createDataPartition(y = df$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
# plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
df<-data.frame(segmentationOriginal$Class, predictors)
inTrain<-createDataPartition(y = df$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
View(train)
View(train)
plot(modFit$finalModel, uniform=FALSE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
df<-data.frame(segmentationOriginal$Class, predictors)
inTrain<-createDataPartition(y = df$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
df<-data.frame(segmentationOriginal$Class, predictors)
inTrain<-createDataPartition(y = df$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
df<-data.frame(segmentationOriginal$Class, predictors)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain<-createDataPartition(y = segmentationOriginal$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
View(segmentationOriginal)
segmentationOriginal$PerimCh1==2
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain<-createDataPartition(y = segmentationOriginal$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
traina<-train[train$PerimStatusCh1==2,]
modFit<-train(Class ~ ., method="rpart", data=traina)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
?train
traina<-train[train$PerimStatusCh1==2,]
modFit<-train(Class ~ ., method="rpart", data=traina)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain<-createDataPartition(y = segmentationOriginal$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
trainb<-train[train$VarIntenCh4==100,]
modFit<-train(Class ~ ., method="rpart", data=trainb)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
modFit<-train(Class ~ ., method="rpart", data=trainb)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
inTrain<-createDataPartition(y = segmentationOriginal$Class, p = .8, list = FALSE)
train<-segmentationOriginal[inTrain,]
test<-segmentationOriginal[-inTrain,]
trainb<-train[train$VarIntenCh4==100,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = FALSE, all = TRUE, cex=.8)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
data<-segmentationOriginal
inTrain<-data$Case=="Train"
train<-data[inTrain,]
test<-data[-inTrain ,]
modFit<-train(Class ~ ., method="rpart", data=train)
print(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = FALSE, all = TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = FALSE, all = TRUE, cex=.8)
plot(modFit$finalModel, uniform = TRUE )
text(modFit$finalModel, use.n = FALSE, all = TRUE, cex=.8)
library("pgmm", lib.loc="\\\\nyfs01/_asgoldbe$/My Documents/R/win-library/3.2")
library(pgmm)
library(pgmm)
data(olive)
olive<-olive[,-1]
library(pgmm)
data(olive)
olive<-olive[,-1]
library(pgmm)
data(olive)
olive<-olive[,-1]
View(olive)
library(pgmm)
data(olive)
olive<-olive[,-1]
inTrain<-createDataPartition(olive$Area, p = .8)
otrain<-olive[inTrain,]
otest<-olive[-inTrain,]
library(pgmm)
data(olive)
olive<-olive[,-1]
inTrain<-createDataPartition(olive$Area, p = .8, list = TRUE)
otrain<-olive[inTrain,]
otest<-olive[-inTrain,]
inTrain<-createDataPartition(olive$Area, p = .8, list = TRUE)
otrain<-olive[inTrain,]
otest<-olive[-inTrain,]
nTrain<-createDataPartition(olive$Area, p = 0.80, list = TRUE)
otrain<-olive[inTrain,]
olive<-olive[,-1]
library(pgmm)
data(olive)
olive<-olive[,-1]
inTrain<-createDataPartition(olive$Area, p = 0.80, list = TRUE)
otrain<-olive[inTrain,]
otest<-olive[-inTrain,]
inTrain<-createDataPartition(Area, p = 0.80, list = TRUE)
inTrain<-createDataPartition(olive$Area, p = 0.80)
otrain<-olive[inTrain,]
treeMod<-train(Area ~ ., data=olive, method="rpart2")
newdata=as.datsa.frame(t(colMeans(olive)))
newdata=as.data.frame(t(colMeans(olive)))
predict(treeMod, newdata)
library(pgmm)
data(olive)
olive<-olive[,-1]
treeMod<-train(Area ~ ., data=olive, method="rpart2")
newdata=as.data.frame(t(colMeans(olive)))
predict(treeMod, newdata)
treeMod$finalModel
plot(treeMod$finalModel)
text(treeMod$finalModel, use.n = FALSE, all = TRUE, cex=.8)
library(pgmm)
data(olive)
olive<-olive[,-1]
treeMod<-train(as.factor(Area) ~ ., data=olive, method="rpart2")
newdata=as.data.frame(t(colMeans(olive)))
predict(treeMod, newdata)
treeMod<-train(as.factor(Area) ~ ., data=olive, method="rpart2"))
library(pgmm)
data(olive)
olive<-olive[,-1]
olive$Area<-as.factor(olive$Area)
treeMod<-train(Area ~ ., data=olive, method="rpart2")
newdata=as.data.frame(t(colMeans(olive)))
predict(treeMod, newdata)
treeMod$finalModel
library(pgmm)
data(olive)
olive<-olive[,-1]
olive$Area<-as.factor(olive$Area)
treeMod<-train(Area ~ ., data=olive, method="rpart2")
newdata=as.data.frame(t(colMeans(olive)))
predict(treeMod, newdata)
treeMod$finalModel
text(treeMod$finalModel, use.n = FALSE, all = TRUE, cex=.8)
library(pgmm)
data(olive)
olive<-olive[,-1]
olive$Area<-as.factor(olive$Area)
treeMod<-train(Area ~ ., data=olive, method="rpart2")
newdata=as.data.frame(t(colMeans(olive)))
predict(treeMod, newdata)
treeMod$finalModel
text(treeMod$finalModel, use.n = TRUE, all = TRUE, cex=.8)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
set.seed(13234)
logitMod<-train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial" )
logitMod
missClass<-function(values, prediction){sum(((prediction > 0.5)*1)!=values)/length(values)}
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train <- sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA <- SAheart[train,]
testSA <- SAheart[-train,]
set.seed(13234)
logitMod<-train(chd ~ age + alcohol + obesity + tobacco +
typea + ldl, data=trainSA, method="glm",
family="binomial" )
missClass<-function(values, prediction){sum(((prediction > 0.5)*1)!=values)/length(values)}
predictTrain<-predict(logitMod, trainSA)
predictTest<-predict(logitMod, testSA)
missClass(trainSA$chd, predictTrain)
missClass(testSA$chd, predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
```{r}
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
# head(vowel.train)
# head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library(caret)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
# head(vowel.train)
# head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
?randomForest2Rules
library(rattle)
library(ElemStatLearn)
library(caret)
library(rattle)
data(vowel.train)
data(vowel.test)
# head(vowel.train)
# head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library(ElemStatLearn)
library(caret)
library(rpart)
library(AppliedPredictiveModeling)
library(pgmm)
data(vowel.train)
data(vowel.test)
# head(vowel.train)
# head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
library(randomForest)
library(ElemStatLearn)
library(caret)
library(rpart)
library(AppliedPredictiveModeling)
library(pgmm)
library(randomForest)
data(vowel.train)
data(vowel.test)
# head(vowel.train)
# head(vowel.test)
dim(vowel.train) # 528  11
dim(vowel.test) # 462  11
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modelRf <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
order(varImp(modelRf), decreasing=T)
varImp(modelRf)
order(varImp(modelRf))
order(varImp(modelRf), decreasing = T)
load("E:/Coursera/Regression/RegModelsPA/final.RData")
setwd("E:/Coursera/Regression/RegModelsPA")
source('~/.active-rstudio-document', encoding = 'UTF-8', echo=TRUE)
getwd)
getwd()
library(knitr)
library(stats)
library(ggplot2)
library(reshape2)
library(dplyr)
library(car)
library(corrplot)
library(graphics)
data(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
mtcars$am <- factor(mtcars$am,labels=c('Automatic','Manual'))
data<-mtcars[,-7]
fit<-lm(mpg~am, mtcars[,-c(7)])
t.test(mtcars[,-7]$mpg~mtcars[,-7]$am)
xt<-summary(fit)$coefficients
kable(xt, caption = "Table 1: Linear Regression Coefficients for Automatic vs. Manual Transmission")
bestfit<-step(lm(mpg~., mtcars[,-c(7)]), direction = "both")
bestmodel<-bestfit$call
bfform<-bestmodel$formula
bfform<-paste(bfform[c(2,1,3)], collapse = "")
allAIC=extractAIC(lm(mpg ~ ., mtcars[,-7]))
fitAIC=extractAIC(lm(mpg ~ am, mtcars[,-7]))
bestAIC=extractAIC(bestfit)
tblAIC<-as.data.frame(rbind("mpg ~ am"= fitAIC[2],"mpg ~ ." = allAIC[2],"mpg ~ cyl + hp + wt + am" = bestAIC[2]))
names(tblAIC)<-"AIC"
fitAIC=extractAIC(lm(mpg ~ am, mtcars[,-7]))
allAIC=extractAIC(lm(mpg ~ ., mtcars[,-7]))
bestAIC=extractAIC(lm(mpg ~ cyl + hp + wt + am, mtcars[,-c(7)]))
tblAIC<-as.data.frame(rbind("mpg ~ am"= fitAIC[2],"mpg ~ ." = allAIC[2],"mpg ~ cyl + hp + wt + am" = bestAIC[2]))
names(tblAIC)<-"AIC"
kable(tblAIC, caption = "Comparison of AIC Values of Three Models")
# bestmodel$formula
kable(summary(bestfit)$coefficients)
kable(as.data.frame(summary(aov(mpg~., data))[[1]]))
mtcars<-mtcars[,-c(7)]
mtcars$cyl<-as.numeric(mtcars$cyl)
c1 <- cor(mtcars$wt, mtcars$cyl)
c2<-cor(mtcars$wt, mtcars$disp)
c3<-cor(mtcars$cyl, mtcars$disp)
c4<-as.data.frame(rbind("wt & cyl" = c1, "wt & disp" = c2, "cyl & disp" = c3))
names(c4)<-"correlation"
kable(c4, caption = "Correlation among variables with lowest p-value in analysis of variance model")
fitall<-lm(mpg~., mtcars[,-c(7)])
fitlesshp <- lm(mpg ~ am + cyl + wt, data = mtcars[,-c(7)])
fitsummary<-data.frame(rbind("mpg ~ ."=summary(fitall)$adj.r.squared, "mpg ~ am"=summary(fit)$adj.r.squared, "mpg ~ cyl  + wt + am" = summary(fitlesshp)$adj.r.squared, "mpg ~ cyl + hp + wt + am " = summary(bestfit)$adj.r.squared))
names(fitsummary)<-"Adj. R-squared"
kable(fitsummary)
firstfit<-lm(mpg~am, mtcars[,-c(7)])
fithp<-lm(mpg~am + hp, mtcars[,-7])
final<-anova(firstfit, bestfit)
final$PRF<-final$`Pr(>F)`
library(relaimpo)
bs <- boot.relimp(bestfit, b = 10, type = "lmg", rank = TRUE,diff = TRUE, rela = TRUE)
# bs2=booteval.relimp(bs)
bs2=booteval.relimp(bs, bty="perc", level = 0.95, sort = TRUE, typesel = "lmg")
btbl<-as.data.frame(as.numeric(bs2@mark[1:4])*100)
names(btbl)<-c("% Contribution")
row.names(btbl)<-c("cyl", "hp", "wt", "am")
kable(btbl,caption = "% contribution to R-squared value of best fit model" )
ggplot(mtcars, aes(y=mpg, x=am, col=am), cex=.5) +
geom_boxplot() +
geom_jitter() +
labs(title="Fuel Efficiency (MPG) vs Transmission Type", x="", y="MPG") +
theme(legend.position="none")
pairs(x = mtcars, lower.panel = panel.smooth, upper.panel = NULL)
par(mfrow=c(1,1))
data(mtcars)
corrplot(cor(mtcars), method="number", type="lower", addCoefasPercent = TRUE)
par(mfrow=c(1,1))
par(mfrow=c(2,2))
plot(bestfit)
install.packages("rsconnect")
file.edit('~/.Rprofile')
install.packages("rsconnect")
devtools::install_github()
install.packages("rtools")

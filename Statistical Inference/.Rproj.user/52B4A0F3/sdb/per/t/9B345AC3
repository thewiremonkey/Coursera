{
    "contents" : "---\ntitle: \"Central Limit Theorem\"\nauthor: \"Alyssa Goldberg\"\ndate: '2015-11-21'\noutput:\n  word_document:\n    fig_caption: yes\n    fig_height: 4\n    reference_docx: template.docx\n  pdf_document: default\n  html_document:\n    fig_caption: yes\n    keep_md: yes\n---\n#Introduction\n\nThe Central Limit Theorem (CLT)states that the distribution of averages of iid variables (properly normalized) becomes that of a standard normal as the *sample size $n$ increases*.  This means that it is possible to get an approximation of mean **$\\mu$**, standard deviation **$\\sigma$**, and variance **$\\sigma^2$**, for the whole distribution with only one observed average ($\\bar X_i$) and without knowing the population distribution.\n\n```{r message=FALSE, echo=F}\nrm(list=ls())\n\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(stats)\n# library(reshape2)\nlibrary(ggplot2)\n\n```\n```{r echo=F}\noptions(digits = 4)\n```\n\n```{r seed, echo=F}\nset.seed(127)\n```\n```{r constants, echo=F}\nl = 0.2 #lambda, as prescribed in assignment\nex = 40 #number of exponentials examined\nsims = 1000 #number of simulations\n\ntmean<-1/l #theoretical mean\ntsd<-sqrt(1/.2^2/ex) #theoritical standard deviation\ntvar<-(1/l/sqrt(ex))^2 #theoretical variance\n\n```\n\n#Test the Central Limit Theorem by simulation:\n\n##Some Initial Assumptions\n\nThe theoretical mean ($\\mu$) and variance $\\sigma^2$ of exponential distribution with parameter $\\lambda$ are respectively $1/\\lambda$ and $1/\\lambda^2$,\n\nIf the CLT is true, then:\n\n* The mean of our simulation $\\bar X_n$ should approach $\\mu$\n* The variance of our simulation, $Var_n$ should approach $1/\\lambda^2$\n* The variance of our sample mean, $S^2$ should approach $\\sigma^2/n$\n* The standard deviation $S$ of our sample mean should approach $\\sqrt{\\frac{1}{{\\lambda^2}/n}}$\n\nLet's find out if this is true by using simulation of **random exponentials** with $n$=40 drawn 1,000 times.  \n\n##Set Constants\n* The rate parameter, $\\lambda$ , as prescribed by the assignment, is 0.2 \n* The number of random exponentials to means test, $n$ is 40.\n* The number of simulations of 40 random exponents is 1000\n* The total population, $n$ * 1000 = 40,000\n* Theoretical constants:  \n        - Theoretical means = $\\frac{1}{0.2}$ = `r tmean`  \n        - Standard deviation = $\\sqrt{\\frac{1}{{0.2^2}/40}}$  =`r tsd`  \n        - Variance of sample mean = $\\sigma^2/n$ = `r tvar`\n\n##Create the Population, Draw Samples\n\nDraw 40 samples of exponentials, 1,000 times, producing a matrix with 1000 rows and 40 columns and create a vector of means of each of those 1000 rows\n\n```{r echo=TRUE}\nsmatrix <- matrix(rexp(ex * sims, .2), nrow = sims, ncol=ex) #produce a 1000 x 40 matrix\n\nsmatrixmeans<-data.frame(value=rowMeans(smatrix)) #produce a data frame of the means of the 1000 rows in smatrix\n```\n```{r echo=F}\n# calculate the overall mean of the new data frame\nsmean<-mean(smatrixmeans$value) \n\n# calculate the standard deviation of the new data frame values\nssd<-sd(smatrixmeans$value) \n\n# calculate the variance of the new data frame values\nsvar<-var(smatrixmeans$value)\n```\n\n##Compare Means:\n\nThe theoretical $\\mu$ for a population this size=  $1/\\lambda$ = `r tmean`.  \nThe calculated $\\bar X_n$ = `r smean`  \n\n```{r figure1, echo=F, fig.height=4,warning=FALSE}\npar(mfrow=c(1,2), mar=c(4,4,0.5,0.5)+.01, oma=c(1.5,2,1,1),font.main=1, cex=.5)\n\nhist(smatrix, breaks = 40, main=\"n=40,000\", xlab=paste(\"mean:\", round(mean(smatrix), digits = 4), sep=\" \"))\nabline(v=mean(smatrix), col=\"red\", lwd=1)\nabline(v=tmean, col=\"blue\", lwd=1)\n\nhist(smatrixmeans$value, breaks = 40, main=\"n=40 X 1000\", xlab=paste(\"mean:\", round(mean(smatrixmeans$value), digits = 4), sep=\" \"))\nabline(v=mean(smatrixmeans$value), col=\"red\", lwd=1)\nabline(v=tmean, col=\"blue\", lwd=1)\n```\n\n##Compare Variance of the Sample Mean:\nLet R calculate the sample mean, sample standard deviation and variance of the sample mean:\n```{r}\nsmean<-mean(smatrixmeans$value) #sample mean\nssd<-sd(smatrixmeans$value) #standard deviation of sample means\nsvar<-var(smatrixmeans$value) #variance of sample means\n```\nProducing:\n\nTheoretical Values | |Sample Values  \n------------- |---|-------------\n$\\mu$ = `r tmean`  | | $\\bar X_n$ = `r smean`\n$\\sigma^2$ = `r tvar`  | | $S^2$ = `r svar`\n$\\sigma$ = `r sqrt(1/.2^2/ex)`| | $S$ = `r ssd`\n\n##Compare Density Distribution:\n\n```{r echo=F}\nsq<-quantile(smatrixmeans$value, probs = c(0.25, 0.5, 0.75))\nnq<-qnorm(p = c(0.25, 0.5, 0.75), mean = tmean, sd = tsd)\ndsummary<-data.frame(rbind(sq,nq),row.names = c(\"sample\",\"normal\"))\nnames(dsummary)<-c(\"25%\", \"50%\", \"75%\")\n\n```\nAs the number of means of sample means ($n$ times the number of simulations) increases, the density distribution should more closely resemble the normal density distribution:  \n```{r kable, align=\"c\", echo=F}\nkable(dsummary,align = \"c\")\n\n```\n\nA Quantile-Quantile plot, displaying both the sorted theoretical normal distribution of means of a large sample (straight line) vs the sorted distribution of calculated means (plot points) shows a fairly tight fit, though it varies a bit more at the tails, yet more evidence that the Central Limit Theorem is useful for working with very large data sets.\n\n```{r  echo=F,}\npar(mar=c(3,3,4,0)+.1, oma=c(1.5,2,1,1))\n```\n```{r fig.height=4}\nqqnorm(smatrixmeans$value, col=rgb(.333, 0.42, .18, 0.5))\nqqline(smatrixmeans$value, col=\"red\", lwd=1.5)\n\n```\n\nWe can see that the behavior of large samples approaches that of the theoretical normal for Mean, Variance and Density, the closer we get to the theoretical Mean, Variance and Density.\n\n\n\n####APPENDIX\n\n##Libraries:\n```{r message=FALSE, results=\"asis\"}\nlibrary(knitr)\nlibrary(dplyr)\nlibrary(stats)\nlibrary(ggplot2)\n\n```\n##Density Plot Theoretical vs. Sample\n\nTo compare densities, we can overlay a density plot for the distribution of the calculated sample means with a theoretical normal distribution density (the classic $bell$ curve) to test this. \n\n```{r echo=T, tidy=TRUE, fig.width=4, fig.height=3}\n\n#for calculated\nsdx<-svar^2 #density standard deviation\nx.dens <- density(smatrixmeans$value) #create list of densities\ndf.dens <- data.frame(x = x.dens$x, y = x.dens$y) #create a dataframe with densities\nvarplot<-df.dens[df.dens$x>=smean-svar & df.dens$x<=smean+svar,]#subset the density data to the area of the variance\n\ndnorm_limit <- function(x) {\n    y <- dnorm(x, mean = mean(smatrixmeans$value), sd=sqrt((tmean^2)/ex))\n    y[x < tmean-tvar  |  x > tmean +tvar ] <- NA\n    return(y)\n}\n\n# Normal vs Sample Plot\np <- ggplot(data.frame(x=c(min(smatrixmeans$value),max(smatrixmeans$value))), aes(x=x))\n\np + stat_function(fun=dnorm_limit, geom=\"area\", fill=\"blue\", alpha=0.2) +\n    stat_function(fun=dnorm, args=list(mean(smatrixmeans$value), sd=sqrt((tmean^2)/ex)), col=\"blue\",lwd=1, lty=2)+\n        geom_density(data=smatrixmeans, aes(value),alpha=.25, col=\"red\" , lwd=1)+\n        geom_area(data=varplot, aes(x=x,y=y), fill = \"red\", alpha=.25)+\n        geom_vline(xintercept=tmean, stat = \"vline\", col=\"blue\")+\n        geom_vline(xintercept=smean, stat = \"vline\", col=\"red\")+\n        xlab(\"Theoretical Normal vs Sample Densities\")+\n        theme_bw()\n\n```\n",
    "created" : 1448075996689.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1895045867",
    "id" : "9B345AC3",
    "lastKnownWriteTime" : 1448226582,
    "path" : "D:/Coursera/Statistical Inference/Stat_Inf_Project.RMD",
    "project_path" : "Stat_Inf_Project.RMD",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}